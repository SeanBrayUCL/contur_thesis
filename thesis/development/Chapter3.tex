\chapter{Profiling Contur}
\label{chapterlabel3}

Before any attempt can be made to optimise code within \textbf{Contur}, it is first necessary to identify processes within the code where potential inefficiencies exist and we can make improvements. The best way to do this is to perform a profile of the code. A good profile should give us visibility not just on the total runtime of \textbf{Contur}, but how this run time breaks down between the different processes that compose a \textbf{Contur} run. 

This section will outline the steps taken to produce a profile of \textbf{Contur} and how we used the results. We will start by introducing \textbf{cProfile}, which is the Python profiler which was used to carry out the profile. Then we will discuss \textbf{Snakeviz} and \textbf{gprof2dot}, these are the two tools which we used to visualise the profiling results produced by \textbf{cProfile}. Finally we will conclude the section by performing an initial profile of the \textbf{Contur} package before any code optimisation was attempted. This initial profile will serve as our benchmark to measure the effectiveness of our later attempts to improve the run time performance of \textbf{Contur}.

First however let us briefly consider why it is a worthwhile effort to try and improve the runtime of \textbf{Contur} code.

\section{Why attempt to optimise Contur?}
The obvious answer to the question \say{Why attempt to optimise \textbf{Contur}?} is simple that we will have code that runs faster. The immediate benefit of faster code for a researcher using \textbf{Contur} is that the wait time from run initiation to results is reduced, all else equal this should increase productivity.

We can argue further though that faster code increases the range of analysis that a researcher can perform with \textbf{Contur}r. This argument follows from the observation that there likely exists a runtime above which \textbf{Contur} becomes impractical to use as a research tool\footnote{To take an extreme example, if the code takes over 24 hours to run, its utility to a researcher will be much less than code that takes under an hour to run.}. If we combine with this the observation that will be discussed later in Chapter \ref{chapterlabel4} that the runtime increases with the size of the grid used, then we can see that runtime puts an upper bound on the size of the grid that can be run with \textbf{Contur}. Improving run time will thus likely increase this upper bound which would allow researchers either to increase the span of a parameter space they evaluate, or look a the parameter space with a greater level of granularity.

A final obvious benefit of run time improvements follows from the fact that currently grids that are too large to run locally will be run on a HPC cluster. Increasing the range of grids that can be run locally will thus decrease the volume of runs going to the cluster, saving valuable CPU resources. Additionally for grids that still need to go to the cluster, making \textbf{Contur} code more efficient will reduce wasteful usage of the HPC CPU resources.

\section{Profiling with cProfile}

\subsection{Why cProfile?}
Let us consider some of the features we ideally require from our chosen profiler. At a minimum a profiler must obviously be able to time how long it takes our code to run. This basic requirement is essential to be able to determine if our attempted improvements to the code do in fact actually improve run performance. In addition to just providing the total run time of \textbf{Contur} we will also require our profiler to provide a split of the runtime among the functions/sub-functions which compose \textbf{Contur}. A split of the run time like this will highlight parts of the code that consume disproportionately large amounts of CPU or are repetitively called, suggesting optimisation improvements can be made.

\textbf{cProfile}\cite{cProfile} is a module within the Python standard library which meets these requirements. Our main motivations for using \textbf{cProfile} are as follows:

\begin{itemize}
\item Provides a full profile of program with output include total run time, time taken at each individual step, and number of calls to individual functions;
\item Easy to save the output of the profile in prof files which can then be read by tools built to visualize profiling results;
\item Performing the profile with \textbf{cProfile} is quick and easy and requires minimal new code;
\end{itemize}

\subsection{Using cProfile}
We will demonstrate the usage of \textbf{cProfile} by profiling the last version of \textbf{Contur} which existed before any optimisation attempts were made\footnote{The version can be found in commit \href{https://gitlab.com/hepcedar/contur/-/tree/49a67e039cf93c88b39dade3dfb7c5f03e780fb2}{49a67e03}}. All \textbf{Contur} code can be found in the main \textbf{Contur} repository\cite{contur_main}, additionally all code contributions for this thesis can also be found as a commits in the main repository. 

For the demonstration we will walk through the steps to profile a single \textbf{YODA} file. The steps required to perform the profile on a \textbf{Contur} grid run are the same, so the in the conclusion for this chapter we will just provide the results of the profile for the grid run without repeating the walk through.

The simplest way of performing a profile with \textbf{cPorfile} is via \textbf{cProfile's} run method. To profile \textbf{Contur} using the run method we just pass \textbf{Contur's} main function to the run method. We can make this adjustment to \textbf{Contur's} code by updating the main run script\footnote{Can be found \href{https://gitlab.com/hepcedar/contur/-/blob/main/bin/contur}{here}} as follows 

\begin{minted}{python}

import cProfile

if __name__ == "__main__":
       cls_args = get_args(sys.argv[1:],'analysis')
       cProfile.run("main(cl_args)", sort=cumtime)

\end{minted}


After updating the run script as above we can now run \textbf{Contur} as normal to get the below terminal output from the profile

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{plots/example_profile.png}
\caption{Output of cProfile run method}
\label{fig:ep}
\end{figure}

From figure \ref{fig:ep} above we can summarise the main output from the single \textbf{YODA} file \textbf{Contur} run:

\begin{itemize}
\item From line one of the profiling results we can see that the run had c.a. 17 million function calls and took c.a. 20 seconds to run;
\item The next line tells us that we are ordering the profiling results by cumulative time (\texttt{cumtime} column). The cumulative time for a function is the time spent to run a function and all other functions called within the function (so the \texttt{cumtime} for the main function will be the total run time of the program as all other functions are called within main);
\item From line three on we have the profiling information for the functions and sub-functions which compose the \textbf{Contur}  run. The main columns which stand out here are \texttt{ncalls} which gives the number of calls made to the function, \texttt{tottime} which gives the total time spent in the function excluding calls to sub functions and finally \texttt{cumtime} which as already explained gives the run time for each function including all the calls to sub functions.;
\end{itemize}

The above profiling is already useful, it gives us things like the run time and the break down of the run time between the components of \textbf{Contur} . However the printed results in the current form are not very readable, a detailed knowledge of the functions that compose \textbf{Contur} would be needed to take any advantage of the run time broken down by components in its current form. Additionally we don't just want to print result to the terminal and work from there, we would preferable save the profiling results to some file format so our results are reusable across time. 

To meet both these objectives for the profiling we  from here on we will print the data from our profile into \say{.prof} files which can then be read by tools which help visualise the profiling results. We do this by introducing the Profile class of \textbf{cProfile} and using this to perform our profiles from here on in as opposed to using the run method, the updated code to perform the profiling with the \textbf{cProfile} class is given below.

\begin{minted}{python}

import cProfile, pstats, io

if __name__ == "__main__":
       cls_args = get_args(sys.argv[1:],'analysis')
       
       pr = cProfile.Profile()
       pr.enable()
       
       main(cl_args)
       
       pr.disable()
       pr.dump_stats('outfile.prof'')
\end{minted}


\section{Visualizing Profiling Results}

To visualise our profiling results we will use two open source tools \textbf{Snakeviz} and \textbf{gprof2dot}. As what follows will show, we can use both of these tools in a complementary way, as opposed to a simple choose of one or the other, to help make best of use of the profiling data we produce with \textbf{cProfile}.

\subsection{Snakeviz}\label{snakeviz}
\textbf{Snakeviz}\cite{snakeviz} is a browser based graphical viewer for the output of Python's \textbf{cProfile} profiler module. \textbf{Snakeviz} can easily be pip installed with the following terminal command

\begin{minted}{bash}
  $ pip install snakeviz
\end{minted}

once installed we can invoke \textbf{Snakeviz} to visualise an arbitrary .prof file as follows

\begin{minted}{bash}
  $ snakeviz profile_file.prof
\end{minted}

After invoking \textbf{Snakeviz} as outlined above the web browser interface for the tool will open and the user can explore the profiling results. \textbf{Snakeviz} allows user interaction to adjust how results are rendered, the two main plotting options available in \textbf{Snakeviz} are icicle plots and sunburst plots\footnote{A nice overview of these plots in \textbf{Snakeviz} can be found \href{https://www.machinelearningplus.com/python/cprofile-how-to-profile-your-python-code/}{here}}. 

From here on we will use \textbf{Snakeviz's} icicle plot to explore profiling results, additionally due to the constraints of the static form of this document is written in we will just examine static snapshots of the overall display in \textbf{Snakeviz's} viewer. These static snapshots of the \textbf{Snakeviz} viewer are sufficient to summarise profiling results. Using \textbf{Snakeviz's} viewers ability to adjust rendering though can be useful to get a feel and understanding for new profiling results, the interested reader is recommended to play around with \textbf{Snakeviz's} viewer functionality further.

Below in figure \ref{fig:single_yoda_start_profile_snakeviz} we show a snapshot of an icicle plot from a profile of our initial starting \textbf{Contur} code on a single \textbf{YODA} file. From the figure we can seen that the icicle plot is showing the same information as figure \ref{fig:ep} in just a more visually appealing way, with the addition that in the icicle plot we can see the ordering of the calls to the components of code that compose a \textbf{Contur} run. This ordering is very useful additional information, for example from the ordering it jumps out at us that the call to \texttt{yoda.core} to read the \textbf{YODA} file passed to \textbf{Contur} takes a large proportion of the run time for a single \textbf{YODA} run. From this we can already understand that a lot of the run time for a single \textbf{YODA} run comes from just reading in data. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.3]{plots/initial_single_contur.png}
\caption{\textbf{Contur} single \textbf{YODA} run starting point - Example \textbf{Snakeviz} icicle plot}
\label{fig:single_yoda_start_profile_snakeviz}
\end{figure}

\subsection{gprof2dot}\label{dot_plot}
\textbf{gprof2dot}\cite{gprof2dot} is a python script that converts the output of the \textbf{cProfile} to dot plots. These dot plots can be used to complement the information we get from the icicle plots. The icicle plots and the user interface offered by \textbf{Snakeviz} offer a means to see the absolute run time of our code and how this absolute run time breaks down among the components of the program. The dot plot complements this information by providing a rendering which makes the flow of the code (i.e. the progression of the code from the call to main through the components that compose the program) more easily visible and additionally showing the relative weight run time wise of the components of the code. This visualisation can be useful to both quickly spot bottlenecks in the code and also just to get a better understand of how a large code base works.

\begin{figure}[H]
\centering
\includegraphics[scale=0.2]{plots/initial_contur_single_yoda.png}
\caption{\textbf{Contur} single \textbf{YODA} run starting point - Example \textbf{gprof2dot}}
\label{fig:single_yoda_start_profile_gprof2dot}
\end{figure}

We can see example of the dot plots produced by \textbf{gprof2dot} in figure \ref{fig:single_yoda_start_profile_gprof2dot} above. This plot is visualising the same single \textbf{YODA}  run as in figure \ref{fig:single_yoda_start_profile_snakeviz}, so is a good way of demonstrating the complementary nature of the icicle plot and the dot plots for visualising our profiling results. Following the colouring scheme in the dot plot (red to yellow to green) the observation we previously made using the icicle plot about the weight of data reading in the runtime can be seen in the dot plot where we can see c.a. $42\%$ of run time is spent reading \textbf{YODA} files.

\section{Initial Profile Results}
In the previous section while introducing the visualisation tools we gave the initial profiling results resulting from running \textbf{Contur} on a single \textbf{YODA} file (see figure \ref{fig:single_yoda_start_profile_snakeviz} and \ref{fig:single_yoda_start_profile_gprof2dot} ) before any optimisation of the code was attempted. 

As previously discussed, in practical settings \textbf{Contur} is generally run on a grid of \textbf{YODA} files as opposed to a single \textbf{YODA} file, so along with our initial single \textbf{YODA} run profile we will also perform an initial profile of \textbf{Contur} on a test grid. The grid we use to perform this profile is a $10 \times 10 $ grid, so composed of $100$ \textbf{YODA} files in total, we will use this reference grid throughout to profile \textbf{Contur's} grid run.

In figure \ref{fig:grid_yoda_start_profile} below we see the icicle plot for the grid run, from this we can see that for the grid of 100 \textbf{YODA} files we have a run time of around $1100$ seconds or close to $20$ minutes. 
\begin{figure}[H]
\centering
\includegraphics[scale=0.30]{plots/initial_contur_grid_profile_two.png}
\caption{\textbf{Contur} grid run - icicle plot}
\label{fig:grid_yoda_start_profile}
\end{figure}

We can also see from the plot that the main contribution to the run time seems to be coming from two blocks of the code. This is best seen in the dot plot figure \ref{fig:grid_yoda_start_profile_dot} below where we can see that the \texttt{sort\_blocks()} method contributes c.a. $25\%$ of the run and the \texttt{ts\_to\_pval()} method which contributes c.a. $49\%$, so both of these methods in combination are close to three quarters of the run time for the \textbf{Contur} grid run.

\begin{figure}[H]
\centering
\includegraphics[scale=0.12]{plots/initial_contur_grid_two.png}
\caption{\textbf{Contur} grid run - dot plot}
\label{fig:grid_yoda_start_profile_dot}
\end{figure}




